{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgpoI1mWQbJW"
      },
      "source": [
        "## DA Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yhGe9WnRqzWK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from groq import Groq\n",
        "import json\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nA3Ld_RedFXe"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2j42BuIuTtIv"
      },
      "outputs": [],
      "source": [
        "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Yd9KIZUrq-kv"
      },
      "outputs": [],
      "source": [
        "class DataAnalysisAgent:\n",
        "  def __init__(self, model):\n",
        "    self.data = None\n",
        "    self.data_type = None\n",
        "    self.analysis_results = {}\n",
        "    self.supported_types = [\"tabular\", \"json\"]\n",
        "    self.model = model\n",
        "    self.client = Groq()\n",
        "\n",
        "  def load_data(self, data_path: str):\n",
        "    try:\n",
        "      path = Path(data_path)\n",
        "\n",
        "      if path.suffix == \".csv\":\n",
        "        self.data = pd.read_csv(path)\n",
        "        self.data_type = \"tabular\"\n",
        "      elif path.suffix == \".xlsx\" or path.suffix == \"xls\":\n",
        "        self.data = pd.read_excel(path)\n",
        "        self.data_type = \"tabular\"\n",
        "      elif path.suffix == \".json\":\n",
        "        self.data = pd.read_json(path)\n",
        "        self.data_type = \"json\"\n",
        "      else:\n",
        "        raise Exception(\"File type not supported yet\")\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception(f\"Error loading data: {str(e)}\")\n",
        "\n",
        "  # def get_columns_type(self):\n",
        "  #   dtypes_dict = self.data.dtypes.to_dict()\n",
        "  #   data_map = {}\n",
        "  #   for key, value in dtypes_dict.items():\n",
        "  #     if str(value) == \"float64\" or \"int64\":\n",
        "  #       data_map[str(key)] = \"numerical\"\n",
        "  #     elif str(value) == \"bool\":\n",
        "  #       data_map[str(key)] = \"bool\"\n",
        "  #     elif str(value) == \"object\":\n",
        "  #       data_map[str(key)] = \"categorical\"\n",
        "  #   return data_map\n",
        "\n",
        "\n",
        "  # I am still trying to fix these\n",
        "  def plot_distribution(self, column):\n",
        "    if column not in self.data.columns:\n",
        "      raise Exception(\"Column not present in the dataset\")\n",
        "    else:\n",
        "      sns.histplot(self.data[column], kde=True)\n",
        "      plt.title(f\"Distribution of {column}\")\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  def analyze(self):\n",
        "    numeric_cols = self.data.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "    analysis = {\n",
        "        'summary_stats': self.data.describe(include=\"all\").to_dict(),\n",
        "        'missing_values': self.data.isnull().sum().to_dict(),\n",
        "        'unique_values': {col: self.data[col].nunique() for col in self.data.columns},\n",
        "        'skewness': self.data.skew().to_dict(),\n",
        "        'kurtosis': self.data.kurtosis().to_dict()\n",
        "    }\n",
        "    if len(numeric_cols) > 1:\n",
        "      analysis['correlations'] = self.data[numeric_cols].corr().to_dict()\n",
        "    for key, value in analysis.items():\n",
        "      self.analysis_results[key] = value\n",
        "    return analysis\n",
        "\n",
        "  def _format_results(self, results, indent: int = 0) -> str:\n",
        "      \"\"\"Format analysis results for the report.\"\"\"\n",
        "      formatted = []\n",
        "      for key, value in results.items():\n",
        "          if isinstance(value, dict):\n",
        "              formatted.append(f\"{'  ' * indent}- {key}:\")\n",
        "              formatted.append(self._format_results(value, indent + 1))\n",
        "          else:\n",
        "              formatted.append(f\"{'  ' * indent}- {key}: {value}\")\n",
        "      return \"\\n\".join(formatted)\n",
        "\n",
        "  def generate_report(self) -> str:\n",
        "        \"\"\"Generate a comprehensive analysis report.\"\"\"\n",
        "\n",
        "        report = [\n",
        "            \"# Data Analysis Report\",\n",
        "            \"\\n## Dataset Overview\",\n",
        "            f\"- Data Type: {self.data_type}\",\n",
        "            f\"- Dataset Shape: {self.data.shape}\"\n",
        "        ]\n",
        "\n",
        "        # Add type-specific metadata\n",
        "        if self.data_type == 'tabular':\n",
        "          report.extend([\n",
        "              f\"- Rows: {self.data.shape[0]}\",\n",
        "              f\"- Columns: {self.data.shape[1]}\",\n",
        "              \"\\n### Column Types:\",\n",
        "          ])\n",
        "            # report.extend([\n",
        "\n",
        "            #     \"\\n### Column Types:\",\n",
        "            #     *[f\"- {k}: {len(v)} columns\" for k, v in self.metadata['column_types'].items() if v]\n",
        "            # ])\n",
        "\n",
        "        # Add analysis results\n",
        "        report.append(\"\\n## Analysis Results\")\n",
        "        for analysis_type, results in self.analysis_results.items():\n",
        "            report.extend([\n",
        "                f\"\\n### {analysis_type.title()}\",\n",
        "                self._format_results(results)\n",
        "            ])\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "  def run_conversation(self, query):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a data analysis agent. You have a few functions available for analysis. You take in the data, decide which function to use and do you best to answer the user's query about the data\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": query,\n",
        "        }\n",
        "    ]\n",
        "    # Define the available tools (i.e. functions) for our model to use\n",
        "    tools = [\n",
        "        {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"analyze\",\n",
        "            \"description\": \"Performs a detailed analysis of the dataset stored in the class. It generates statistical summaries, missing value counts, unique value counts, skewness, kurtosis, and correlations for numeric columns, providing key insights for exploratory data analysis (EDA).\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},  # No additional parameters required\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"generate_report\",\n",
        "            \"description\": \"Generates a comprehensive analysis report of the dataset stored in the class. The report includes dataset overview, column types, and detailed analysis results such as summary statistics, missing values, unique values, skewness, kurtosis, and correlations.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},  # No additional parameters required\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"plot_distribution\",\n",
        "            \"description\": \"Plots the distribution of a specified column in the dataset using a histogram with a KDE overlay. This is useful for visualizing the frequency distribution and the underlying data shape.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"column\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The name of the column for which the distribution is to be plotted.\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"column\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "    ]\n",
        "    response = self.client.chat.completions.create(\n",
        "        model=self.model,\n",
        "        messages=messages,\n",
        "        stream=False,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "        max_tokens=4096\n",
        "    )\n",
        "    response_message = response.choices[0].message\n",
        "    tool_calls = response_message.tool_calls\n",
        "    if tool_calls:\n",
        "      available_functions = {\n",
        "            \"analyze\": self.analyze,\n",
        "            \"generate_report\": self.generate_report,\n",
        "            \"plot_distribution\": self.plot_distribution\n",
        "        }\n",
        "      messages.append(response_message)\n",
        "\n",
        "\n",
        "      for tool_call in tool_calls:\n",
        "        function_name = tool_call.function.name\n",
        "        function_to_call = available_functions.get(function_name)\n",
        "\n",
        "        if not function_to_call:\n",
        "            raise Exception(f\"Function {function_name} is not available.\")\n",
        "\n",
        "\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "\n",
        "        if function_name == \"analyze\":\n",
        "            function_response = json.dumps(function_to_call(), default=str)\n",
        "        elif function_name == \"generate_report\":\n",
        "            function_response = function_to_call()\n",
        "        elif function_name == \"plot_distribution\":\n",
        "            column = function_args.get(\"column\")\n",
        "            if not column:\n",
        "                raise Exception(\"Missing 'column' argument for plot_distribution.\")\n",
        "            function_response = function_to_call(column=column)\n",
        "        else:\n",
        "            raise Exception(f\"Unexpected function: {function_name}\")\n",
        "\n",
        "\n",
        "\n",
        "        messages.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    second_response = self.client.chat.completions.create(\n",
        "        model=self.model,\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "\n",
        "    return second_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iW5MZ-IO6Zuw"
      },
      "outputs": [],
      "source": [
        "agent = DataAnalysisAgent(model=\"llama3-groq-70b-8192-tool-use-preview\")\n",
        "agent.load_data(\"/content/sample_data/california_housing_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z9nvstBJtZgP",
        "outputId": "66db86b7-442d-4ef3-b257-624486d28e30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The mean of the median_house_value is 207,300.91, the median is 180,400, and the standard deviation is 115,983.76.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"What are the mean, median, and standard deviation of the median_house_value column?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "cAh6Ht4qxqzu",
        "outputId": "1b2edefd-c7b2-4e40-b109-e9bd899c3a4d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There are a few negative correlations worth noting. For instance, there\\'s a negative correlation between \"housing_median_age\" and \"total_bedrooms\" with a value of -0.320434. Also, \"housing_median_age\" has a negative correlation with \"total_rooms\" at -0.360984.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"Is there any negative correlation between numerical columns? If so, which ones?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zR-3wjyiyfEF",
        "outputId": "d3d01111-ce28-4b95-c7a5-007a365aa152"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The average median house value for each category of ocean proximity is as follows: 'NEAR BAY' with $604500, 'NEAR OCEAN' with $679000, 'INLAND' with $291000, and 'ISLAND' with $450000.\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"What is the average median_house_value for each category of ocean_proximity?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJdyVEpXyq_M",
        "outputId": "6a85053b-e9ab-48bf-eae8-4b4d58bc2472"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The ocean_proximity category with the highest average median_income is 'NEAR_BAY', with an average median income of $4.5.\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run_conversation(query = \"Which ocean_proximity category has the highest average median_income?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87vkLF05GGN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYP6pbIKQYiK"
      },
      "source": [
        "## RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rXuzxn5v5GwQ"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eBb5gZ5K-8ht"
      },
      "outputs": [],
      "source": [
        "class RAG:\n",
        "    data_agent: DataAnalysisAgent\n",
        "    model_name: str\n",
        "    pdf_directory: str\n",
        "\n",
        "    def __init__(self, data_agent: DataAnalysisAgent, model_name: str, pdf_directory: str):\n",
        "        self.data_agent = data_agent\n",
        "        self.model_name = model_name\n",
        "        self.pdf_directory = pdf_directory\n",
        "        self.vector_store = None\n",
        "\n",
        "    def load_and_process_pdfs(self):\n",
        "        loader = PyPDFDirectoryLoader(self.pdf_directory)\n",
        "        documents = loader.load()\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "        splits = text_splitter.split_documents(documents)\n",
        "\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        self.vector_store = FAISS.from_documents(splits, embeddings)\n",
        "\n",
        "    def create_chain(self):\n",
        "        llm = ChatGroq(\n",
        "            model_name=self.model_name\n",
        "        )\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Context: {context}\n",
        "        Data Analysis Results: {analysis_results}\n",
        "\n",
        "        Question: {input}\n",
        "\n",
        "        Provide an answer using both the context from the documents and the data analysis insights.\n",
        "        If the answer is not provided in the analysis and the context, then simply say so and suggest the best possible solution.\n",
        "        \"\"\")\n",
        "\n",
        "        document_chain = create_stuff_documents_chain(\n",
        "            llm=llm,\n",
        "            prompt=prompt\n",
        "        )\n",
        "\n",
        "        retrieval_chain = create_retrieval_chain(\n",
        "            self.vector_store.as_retriever(),\n",
        "            document_chain\n",
        "        )\n",
        "\n",
        "        return retrieval_chain\n",
        "\n",
        "    def query(self, question: str) -> str:\n",
        "        if not self.vector_store:\n",
        "            self.load_and_process_pdfs()\n",
        "\n",
        "        analysis_results = self.data_agent.analyze()\n",
        "        chain = self.create_chain()\n",
        "\n",
        "        response = chain.invoke({\n",
        "            \"input\": question,\n",
        "            \"analysis_results\": json.dumps(analysis_results, default=str)\n",
        "        })\n",
        "\n",
        "        return response[\"answer\"]\n",
        "\n",
        "    def get_data_distribution(self, column: str):\n",
        "        return self.data_agent.plot_distribution(column)\n",
        "\n",
        "    def get_full_report(self) -> str:\n",
        "        return self.data_agent.generate_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KEbnlnUX_Qq1"
      },
      "outputs": [],
      "source": [
        "rag = RAG(data_agent=agent, model_name=\"llama-3.1-8b-instant\", pdf_directory=\"/content/pdfs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VS2zBBWUDK3O"
      },
      "outputs": [],
      "source": [
        "answer = rag.query(\"What are the mean, median, and standard deviation of the median_house_value column? Also, what is the best model for price prediction? How does the measures f central tendency affect the model selection?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdGfaXcKD4GV",
        "outputId": "bb80c444-0aa6-4692-a91b-9052bdec9d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided data analysis results, we can answer the questions as follows:\n",
            "\n",
            "1. What are the mean, median, and standard deviation of the median_house_value column?\n",
            "\n",
            "From the data analysis results, we can see that the median_house_value column has the following statistics:\n",
            "\n",
            "- Mean: 207300.91235294117\n",
            "- Median: 180400.0\n",
            "- Standard Deviation: 115983.76438720913\n",
            "\n",
            "2. What is the best model for price prediction?\n",
            "\n",
            "According to the text, the best model for price prediction is the Random Forest model, which has an MSE (Mean Squared Error) of 0.290. This is based on the performance of each model on the test set, as shown in Table 3.\n",
            "\n",
            "3. How do the measures of central tendency affect the model selection?\n",
            "\n",
            "The measures of central tendency (mean, median, and standard deviation) can provide insights into the distribution of the data and help in model selection. In this case, the median_house_value column has a high standard deviation (115983.76438720913), indicating that the data is highly skewed. The median (180400.0) is lower than the mean (207300.91235294117), which suggests that there are some extreme values in the data that are pulling the mean upwards.\n",
            "\n",
            "The Random Forest model, which is the best model for price prediction, is likely able to handle the high skewness and outliers in the data, as it is a robust and flexible model that can learn complex relationships between variables. The other models, such as Ridge Linear Model and Gradient Boosting, may not perform as well on this dataset due to the high skewness and outliers.\n",
            "\n",
            "In summary, the measures of central tendency (mean, median, and standard deviation) provide insights into the distribution of the data and help in model selection. The Random Forest model is the best model for price prediction due to its ability to handle high skewness and outliers in the data.\n"
          ]
        }
      ],
      "source": [
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNE9yt3qEUt-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RAG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
